{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2eaedce-5a28-4f27-b9d8-600b160ade82",
   "metadata": {},
   "source": [
    "# Model Design , Dataset and Train Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12f87bf7-dbd2-47ff-900c-b83625608cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 180 images with labels: {0, 1, 2, 3, 4, 5}\n",
      "Image: ./images\\elephant\\input_10.png, Label: 0\n",
      "Image: ./images\\elephant\\input_11.png, Label: 0\n",
      "Image: ./images\\giraffe\\input_11.png, Label: 1\n",
      "Image: ./images\\giraffe\\input_12.png, Label: 1\n",
      "Image: ./images\\kangaroo\\input_11.png, Label: 2\n",
      "Image: ./images\\kangaroo\\input_12.png, Label: 2\n",
      "Image: ./images\\penguin\\input_102.png, Label: 3\n",
      "Image: ./images\\penguin\\input_15.png, Label: 3\n",
      "Image: ./images\\tiger\\input_1.png, Label: 4\n",
      "Image: ./images\\tiger\\input_13.png, Label: 4\n",
      "Image: ./images\\zebra\\input_14.png, Label: 5\n",
      "Image: ./images\\zebra\\input_17.png, Label: 5\n",
      "Starting epoch 1 of 10\n",
      "Processing batch 1/18\n",
      "Processing batch 11/18\n",
      "Epoch 1/10, Loss: 2.3263\n",
      "Starting epoch 2 of 10\n",
      "Processing batch 1/18\n",
      "Processing batch 11/18\n",
      "Epoch 2/10, Loss: 1.6342\n",
      "Starting epoch 3 of 10\n",
      "Processing batch 1/18\n",
      "Processing batch 11/18\n",
      "Epoch 3/10, Loss: 1.3133\n",
      "Starting epoch 4 of 10\n",
      "Processing batch 1/18\n",
      "Processing batch 11/18\n",
      "Epoch 4/10, Loss: 1.1655\n",
      "Starting epoch 5 of 10\n",
      "Processing batch 1/18\n",
      "Processing batch 11/18\n",
      "Epoch 5/10, Loss: 1.0740\n",
      "Starting epoch 6 of 10\n",
      "Processing batch 1/18\n",
      "Processing batch 11/18\n",
      "Epoch 6/10, Loss: 0.6309\n",
      "Starting epoch 7 of 10\n",
      "Processing batch 1/18\n",
      "Processing batch 11/18\n",
      "Epoch 7/10, Loss: 0.5069\n",
      "Starting epoch 8 of 10\n",
      "Processing batch 1/18\n",
      "Processing batch 11/18\n",
      "Epoch 8/10, Loss: 0.4088\n",
      "Starting epoch 9 of 10\n",
      "Processing batch 1/18\n",
      "Processing batch 11/18\n",
      "Epoch 9/10, Loss: 0.3429\n",
      "Starting epoch 10 of 10\n",
      "Processing batch 1/18\n",
      "Processing batch 11/18\n",
      "Epoch 10/10, Loss: 0.2668\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "# Dataset and transformation definitions\n",
    "# Include all relevant dataset and transform code here (as in your current script)\n",
    "\n",
    "# Define a custom PyTorch dataset\n",
    "class AnimalDataset(Dataset):\n",
    "    def __init__(self, data_dir, classes, transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.classes = classes\n",
    "        self.transform = transform\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "\n",
    "        # Load images and their labels\n",
    "        for label, class_name in enumerate(classes):\n",
    "            class_dir = os.path.join(data_dir, class_name)\n",
    "            for img_name in os.listdir(class_dir):\n",
    "                img_path = os.path.join(class_dir, img_name)\n",
    "                self.images.append(img_path)\n",
    "                self.labels.append(label)\n",
    "\n",
    "        # Print the number of loaded images and their labels\n",
    "        print(f\"Loaded {len(self.images)} images with labels: {set(self.labels)}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "# Transformation pipeline for the images\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize images to 224x224\n",
    "    transforms.RandomHorizontalFlip(),  # Randomly flip images horizontally\n",
    "    transforms.RandomRotation(15),     # Randomly rotate images within 15 degrees\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),  # Adjust brightness and contrast\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)),  # Normalize\n",
    "])\n",
    "\n",
    "# Define a simple custom model\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),  # Added another Conv2D layer\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64 * 28 * 28, 256),  # Adjusted dimensions\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "# Initialize weights using Xavier initialization\n",
    "def initialize_weights(m):\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "\n",
    "\n",
    "# Model definition and initialization\n",
    "# Include your model definition and `initialize_weights`\n",
    "\n",
    "# Set up dataset and data loaders\n",
    "data_dir = \"./images\"\n",
    "classes = [\"elephant\", \"giraffe\", \"kangaroo\", \"penguin\", \"tiger\", \"zebra\"]\n",
    "num_classes = len(classes)\n",
    "batch_size = 8\n",
    "num_epochs = 10\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Dataset loading and splitting\n",
    "dataset = AnimalDataset(data_dir, classes, transform=transform)\n",
    "# Display 2 samples per label for debugging\n",
    "label_count = {label: 0 for label in range(len(classes))}\n",
    "for idx in range(len(dataset)):\n",
    "    image, label = dataset[idx]\n",
    "    if label_count[label] < 2:\n",
    "        print(f\"Image: {dataset.images[idx]}, Label: {label}\")\n",
    "        label_count[label] += 1\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, _ = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Model initialization\n",
    "model = SimpleCNN(num_classes=num_classes)\n",
    "model.apply(initialize_weights)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Starting epoch {epoch + 1} of {num_epochs}\")\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        if i % 10 == 0:\n",
    "            print(f\"Processing batch {i + 1}/{len(train_loader)}\")\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    scheduler.step()\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {running_loss / len(train_loader):.4f}\")\n",
    "\n",
    "# Save the model\n",
    "torch.save(model.state_dict(), \"animal_classification_model.pth\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2bf331-77e9-4229-b354-190f02e3fea6",
   "metadata": {},
   "source": [
    "# Test Set, Prediction Defines and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dcd3a50d-07bc-4a04-889c-373fc4765028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 180 images with labels: {0, 1, 2, 3, 4, 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Smartup\\AppData\\Local\\Temp\\ipykernel_41372\\2999166786.py:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"animal_classification_model.pth\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    elephant       0.86      0.75      0.80         8\n",
      "     giraffe       1.00      1.00      1.00         8\n",
      "    kangaroo       0.50      0.67      0.57         3\n",
      "     penguin       1.00      1.00      1.00         5\n",
      "       tiger       0.86      0.86      0.86         7\n",
      "       zebra       1.00      1.00      1.00         5\n",
      "\n",
      "    accuracy                           0.89        36\n",
      "   macro avg       0.87      0.88      0.87        36\n",
      "weighted avg       0.90      0.89      0.89        36\n",
      "\n",
      "Predicted Class: tiger\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Dataset and transformation definitions\n",
    "# Use the same dataset and transform code as in the training notebook\n",
    "\n",
    "# Model definition\n",
    "# Include your model definition\n",
    "\n",
    "# Load dataset and test data\n",
    "data_dir = \"./images\"\n",
    "classes = [\"elephant\", \"giraffe\", \"kangaroo\", \"penguin\", \"tiger\", \"zebra\"]\n",
    "batch_size = 8\n",
    "\n",
    "# Dataset loading and splitting\n",
    "dataset = AnimalDataset(data_dir, classes, transform=transform)\n",
    "_, test_dataset = torch.utils.data.random_split(dataset, [int(0.8 * len(dataset)), len(dataset) - int(0.8 * len(dataset))])\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Load the saved model\n",
    "model = SimpleCNN(num_classes=len(classes))\n",
    "model.load_state_dict(torch.load(\"animal_classification_model.pth\"))\n",
    "model.eval()\n",
    "\n",
    "# Evaluation\n",
    "y_true = []\n",
    "y_pred = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        y_true.extend(labels.numpy())\n",
    "        y_pred.extend(predicted.numpy())\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_true, y_pred, target_names=classes))\n",
    "\n",
    "# Example prediction on a single image\n",
    "def predict_image(image_path, model, transform):\n",
    "    model.eval()\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    if transform:\n",
    "        image = transform(image).unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        output = model(image)\n",
    "        _, predicted = torch.max(output, 1)\n",
    "    return classes[predicted.item()]\n",
    "\n",
    "# Test prediction\n",
    "example_image_path = \"Sumatran_Tiger_Berlin_Tierpark.jpg\"\n",
    "predicted_class = predict_image(example_image_path, model, transform)\n",
    "print(f\"Predicted Class: {predicted_class}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6087d021-e1d4-4d15-96c7-2b4981f474ef",
   "metadata": {},
   "source": [
    "# 1. Performance Analysis\n",
    "Classification Report\n",
    "The model achieved an accuracy of 89% on the test set, which is a strong result. Key highlights include:\n",
    "\n",
    "Elephant: Precision = 0.86, Recall = 0.75, indicating a good balance but room for improvement in recall.\n",
    "Giraffe: Perfect performance (Precision, Recall, and F1-score = 1.00).\n",
    "Kangaroo: Precision = 0.50, Recall = 0.67, suggesting the model predicts this class conservatively.\n",
    "Penguin, Tiger, and Zebra: Performed exceptionally well, with Precision and Recall â‰¥ 0.86.\n",
    "Overall\n",
    "The model is robust but struggles slightly with kangaroo and elephant, likely due to:\n",
    "\n",
    "Data imbalance: If these classes have fewer samples or more noisy images.\n",
    "Visual similarity: Confusion with other classes (e.g., elephant and giraffe in similar environments)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9458f42-8012-4a33-9330-a639c714d599",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
